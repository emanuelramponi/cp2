{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('real_estate_price_size_year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = data[['size','year']]\n",
    "y = data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   168.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 26 Sep 2023</td> <th>  Prob (F-statistic):</th> <td>2.77e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:05:42</td>     <th>  Log-Likelihood:    </th> <td> -1191.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   2389.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>   2397.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-5.772e+06</td> <td> 1.58e+06</td> <td>   -3.647</td> <td> 0.000</td> <td>-8.91e+06</td> <td>-2.63e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>size</th>  <td>  227.7009</td> <td>   12.474</td> <td>   18.254</td> <td> 0.000</td> <td>  202.943</td> <td>  252.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>  <td> 2916.7853</td> <td>  785.896</td> <td>    3.711</td> <td> 0.000</td> <td> 1357.000</td> <td> 4476.571</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>10.083</td> <th>  Durbin-Watson:     </th> <td>   2.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.006</td> <th>  Jarque-Bera (JB):  </th> <td>   3.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.095</td> <th>  Prob(JB):          </th> <td>   0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.080</td> <th>  Cond. No.          </th> <td>9.41e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.41e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      price       & \\textbf{  R-squared:         } &     0.776   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.772   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     168.5   \\\\\n",
       "\\textbf{Date:}             & Tue, 26 Sep 2023 & \\textbf{  Prob (F-statistic):} &  2.77e-32   \\\\\n",
       "\\textbf{Time:}             &     10:05:42     & \\textbf{  Log-Likelihood:    } &   -1191.7   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     2389.   \\\\\n",
       "\\textbf{Df Residuals:}     &          97      & \\textbf{  BIC:               } &     2397.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &   -5.772e+06  &     1.58e+06     &    -3.647  &         0.000        &    -8.91e+06    &    -2.63e+06     \\\\\n",
       "\\textbf{size}  &     227.7009  &       12.474     &    18.254  &         0.000        &      202.943    &      252.458     \\\\\n",
       "\\textbf{year}  &    2916.7853  &      785.896     &     3.711  &         0.000        &     1357.000    &     4476.571     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 10.083 & \\textbf{  Durbin-Watson:     } &    2.250  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.006 & \\textbf{  Jarque-Bera (JB):  } &    3.678  \\\\\n",
       "\\textbf{Skew:}          &  0.095 & \\textbf{  Prob(JB):          } &    0.159  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.080 & \\textbf{  Cond. No.          } & 9.41e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.41e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.776\n",
       "Model:                            OLS   Adj. R-squared:                  0.772\n",
       "Method:                 Least Squares   F-statistic:                     168.5\n",
       "Date:                Tue, 26 Sep 2023   Prob (F-statistic):           2.77e-32\n",
       "Time:                        10:05:42   Log-Likelihood:                -1191.7\n",
       "No. Observations:                 100   AIC:                             2389.\n",
       "Df Residuals:                      97   BIC:                             2397.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -5.772e+06   1.58e+06     -3.647      0.000   -8.91e+06   -2.63e+06\n",
       "size         227.7009     12.474     18.254      0.000     202.943     252.458\n",
       "year        2916.7853    785.896      3.711      0.000    1357.000    4476.571\n",
       "==============================================================================\n",
       "Omnibus:                       10.083   Durbin-Watson:                   2.250\n",
       "Prob(Omnibus):                  0.006   Jarque-Bera (JB):                3.678\n",
       "Skew:                           0.095   Prob(JB):                        0.159\n",
       "Kurtosis:                       2.080   Cond. No.                     9.41e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.41e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sm.add_constant(x1)\n",
    "result = sm.OLS(y,x).fit()\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   285.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 26 Sep 2023</td> <th>  Prob (F-statistic):</th> <td>8.13e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:05:42</td>     <th>  Log-Likelihood:    </th> <td> -1198.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   2401.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   2406.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 1.019e+05</td> <td> 1.19e+04</td> <td>    8.550</td> <td> 0.000</td> <td> 7.83e+04</td> <td> 1.26e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>size</th>  <td>  223.1787</td> <td>   13.199</td> <td>   16.909</td> <td> 0.000</td> <td>  196.986</td> <td>  249.371</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.262</td> <th>  Durbin-Watson:     </th> <td>   2.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.044</td> <th>  Jarque-Bera (JB):  </th> <td>   2.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.117</td> <th>  Prob(JB):          </th> <td>   0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.194</td> <th>  Cond. No.          </th> <td>2.75e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.75e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      price       & \\textbf{  R-squared:         } &     0.745   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.742   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     285.9   \\\\\n",
       "\\textbf{Date:}             & Tue, 26 Sep 2023 & \\textbf{  Prob (F-statistic):} &  8.13e-31   \\\\\n",
       "\\textbf{Time:}             &     10:05:42     & \\textbf{  Log-Likelihood:    } &   -1198.3   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     2401.   \\\\\n",
       "\\textbf{Df Residuals:}     &          98      & \\textbf{  BIC:               } &     2406.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    1.019e+05  &     1.19e+04     &     8.550  &         0.000        &     7.83e+04    &     1.26e+05     \\\\\n",
       "\\textbf{size}  &     223.1787  &       13.199     &    16.909  &         0.000        &      196.986    &      249.371     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  6.262 & \\textbf{  Durbin-Watson:     } &    2.267  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.044 & \\textbf{  Jarque-Bera (JB):  } &    2.938  \\\\\n",
       "\\textbf{Skew:}          &  0.117 & \\textbf{  Prob(JB):          } &    0.230  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.194 & \\textbf{  Cond. No.          } & 2.75e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.75e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.745\n",
       "Model:                            OLS   Adj. R-squared:                  0.742\n",
       "Method:                 Least Squares   F-statistic:                     285.9\n",
       "Date:                Tue, 26 Sep 2023   Prob (F-statistic):           8.13e-31\n",
       "Time:                        10:05:42   Log-Likelihood:                -1198.3\n",
       "No. Observations:                 100   AIC:                             2401.\n",
       "Df Residuals:                      98   BIC:                             2406.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       1.019e+05   1.19e+04      8.550      0.000    7.83e+04    1.26e+05\n",
       "size         223.1787     13.199     16.909      0.000     196.986     249.371\n",
       "==============================================================================\n",
       "Omnibus:                        6.262   Durbin-Watson:                   2.267\n",
       "Prob(Omnibus):                  0.044   Jarque-Bera (JB):                2.938\n",
       "Skew:                           0.117   Prob(JB):                        0.230\n",
       "Kurtosis:                       2.194   Cond. No.                     2.75e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.75e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data['size']\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "result_1 = sm.OLS(y,x).fit()\n",
    "result_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the variable year not only worsens he explanatory power of the model reflected by a lower adjusted R-squared but is also insignificant.\n",
    "# herefore, it shouldd be dropped all together.\n",
    "\n",
    "# The choice of third variable affected the intercept. Whenever you have one variable that is running the model you should not use this model altogether \n",
    "# because the bias of this variable is reflected into the coefficients of the other variables.\n",
    "\n",
    "# The correct approach is to remove it from the regression and run a new one, omittinf the problematic predictor.\n",
    "# There is one more consideration concerning the removal of variables from a model.\n",
    "\n",
    "# Finally, the adjusted R-squared is the basis for comparing regression models.\n",
    "# We compare the SAME DEPENDENT VARIABLE (Y) and the SAME DATASET from TWO MODELS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The F statistics follows an F distribution.  The test is known as the test for overall significance of the model.\n",
    "# The null hypothesis is all the betas are equaul to zero simultaneously. \n",
    "# The alternative Hypothesis is at least one beta defers from zero.\n",
    "\n",
    "# The interpretation is if all betas are zero, then none of he independent variables matter, therefore our model has no merit.\n",
    "\n",
    "# The lower the F statistic, the closer to a non-significant model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumptions\n",
    "\n",
    "# Linearity\n",
    "# The linear regression is the simplest non-trival relationship. It is called linear because the equation is linear. \n",
    "# Each independent variable is multiplied by a coefficiet, and summed up to predict the value of the dependent value.\n",
    "\n",
    "# How can you verify it the relationship between two variables is linear?\n",
    "# The easiest way is to choose an indepnedent variable x1 and plot it against the dependent y on a scatter plot.\n",
    "# If the data points form a pattern thath looks like a straight line, the a linear regression model is suitable.\n",
    "\n",
    "\n",
    "\n",
    "# No Endogeneity\n",
    "# It refers to the prohibition of a link between the idependent varaibles and the errors.\n",
    "# The error thus the difference between the observed values and the predicted values, is correlated with out independent values.\n",
    "# This is a problem referred to as ommited varialbe bias.\n",
    "\n",
    "# Omitted variable \n",
    "# Is introduced to the model when you forget to include a relevant variable. As each indepnedent variable explains y they move together and\n",
    "# are somewhat correlated.\n",
    "\n",
    "# Similary, Y is also explained by the ommited variable, so the also correlated. \n",
    "# Chances are, the ommited variable is also correlated with at least one independent x. \n",
    "# Everything that you do not explain with your model goes int tohe error.\n",
    "\n",
    "# An incorrect exclusion of a variable like in this case, leads to biased and counterintuitive estimates \n",
    "# that are toxic to your regression analysis.\n",
    "# As we saw in our \"Adjustd R-squared\" lecture, leads to inefficient estimates which don`t bias the regression, \n",
    "# and you can inmediately drom them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
